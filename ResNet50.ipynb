{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# *Using ResNet50 pretrained model to classify Concrete Crack images*\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "\n",
    "1.  <a href=\"https://#item31\">Import Libraries and Packages</a>\n",
    "3.  <a href=\"https://#item32\">Define Global Constants</a>\n",
    "4.  <a href=\"https://#item33\">Construct ImageDataGenerator Instances</a>\n",
    "5.  <a href=\"https://#item34\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='item31'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='item32'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Global Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab.\n",
    "\n",
    "1.  We are obviously dealing with two classes, so *num_classes* is 2.\n",
    "2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3.  We will training and validating the model using batches of 100 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "image_resize = 224\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='item34'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training and validation images as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_2/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_2/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Double-click **here** for the solution.\n",
    "\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='item35'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build, Compile and Fit Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.functional.Functional at 0x165e6b7f0>,\n <keras.layers.core.dense.Dense at 0x1670c2040>]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.input_layer.InputLayer at 0x164055100>,\n <keras.layers.convolutional.ZeroPadding2D at 0x164055730>,\n <keras.layers.convolutional.Conv2D at 0x162efb640>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16403ea90>,\n <keras.layers.core.activation.Activation at 0x16411a1f0>,\n <keras.layers.convolutional.ZeroPadding2D at 0x16411aac0>,\n <keras.layers.pooling.MaxPooling2D at 0x164157850>,\n <keras.layers.convolutional.Conv2D at 0x16417b5e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16417b0d0>,\n <keras.layers.core.activation.Activation at 0x164187040>,\n <keras.layers.convolutional.Conv2D at 0x164187790>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164187760>,\n <keras.layers.core.activation.Activation at 0x16418e0a0>,\n <keras.layers.convolutional.Conv2D at 0x164169130>,\n <keras.layers.convolutional.Conv2D at 0x16418e880>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641579a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164198880>,\n <keras.layers.merge.Add at 0x16418e3d0>,\n <keras.layers.core.activation.Activation at 0x1641768b0>,\n <keras.layers.convolutional.Conv2D at 0x16411a3a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16411a400>,\n <keras.layers.core.activation.Activation at 0x164055c40>,\n <keras.layers.convolutional.Conv2D at 0x16419cfd0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16419d8b0>,\n <keras.layers.core.activation.Activation at 0x16418d790>,\n <keras.layers.convolutional.Conv2D at 0x1641a4430>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641a5ee0>,\n <keras.layers.merge.Add at 0x1641ac040>,\n <keras.layers.core.activation.Activation at 0x1641ac130>,\n <keras.layers.convolutional.Conv2D at 0x1641b1fa0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641b57c0>,\n <keras.layers.core.activation.Activation at 0x1641b1e80>,\n <keras.layers.convolutional.Conv2D at 0x1641bdf10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641c0580>,\n <keras.layers.core.activation.Activation at 0x1641bd580>,\n <keras.layers.convolutional.Conv2D at 0x1641c98e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641d10d0>,\n <keras.layers.merge.Add at 0x1641ccf10>,\n <keras.layers.core.activation.Activation at 0x1641cc7f0>,\n <keras.layers.convolutional.Conv2D at 0x1641d9ee0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641d99a0>,\n <keras.layers.core.activation.Activation at 0x1641e7220>,\n <keras.layers.convolutional.Conv2D at 0x1641e7400>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641ccee0>,\n <keras.layers.core.activation.Activation at 0x1641fb430>,\n <keras.layers.convolutional.Conv2D at 0x1641d9610>,\n <keras.layers.convolutional.Conv2D at 0x1641fbf10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16411a6d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164201af0>,\n <keras.layers.merge.Add at 0x164207280>,\n <keras.layers.core.activation.Activation at 0x1642076a0>,\n <keras.layers.convolutional.Conv2D at 0x1641ee3d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16420bd90>,\n <keras.layers.core.activation.Activation at 0x1642192b0>,\n <keras.layers.convolutional.Conv2D at 0x164219130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164212430>,\n <keras.layers.core.activation.Activation at 0x164227340>,\n <keras.layers.convolutional.Conv2D at 0x164227160>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16420bc10>,\n <keras.layers.merge.Add at 0x1641ee430>,\n <keras.layers.core.activation.Activation at 0x1641ccc10>,\n <keras.layers.convolutional.Conv2D at 0x1641d1640>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642205e0>,\n <keras.layers.core.activation.Activation at 0x16417b8e0>,\n <keras.layers.convolutional.Conv2D at 0x1641a44c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641ac0a0>,\n <keras.layers.core.activation.Activation at 0x1642240a0>,\n <keras.layers.convolutional.Conv2D at 0x1641d1c70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642332b0>,\n <keras.layers.merge.Add at 0x1642385e0>,\n <keras.layers.core.activation.Activation at 0x164238940>,\n <keras.layers.convolutional.Conv2D at 0x16421ca60>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164238d60>,\n <keras.layers.core.activation.Activation at 0x1642451c0>,\n <keras.layers.convolutional.Conv2D at 0x164245ca0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164224370>,\n <keras.layers.core.activation.Activation at 0x16424f250>,\n <keras.layers.convolutional.Conv2D at 0x164238af0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164255850>,\n <keras.layers.merge.Add at 0x164260160>,\n <keras.layers.core.activation.Activation at 0x164260790>,\n <keras.layers.convolutional.Conv2D at 0x16424f0a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16424f670>,\n <keras.layers.core.activation.Activation at 0x16427e2b0>,\n <keras.layers.convolutional.Conv2D at 0x16427e790>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16427e700>,\n <keras.layers.core.activation.Activation at 0x16428c250>,\n <keras.layers.convolutional.Conv2D at 0x164260fd0>,\n <keras.layers.convolutional.Conv2D at 0x16428cc70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1641eeb20>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16427edf0>,\n <keras.layers.merge.Add at 0x1642990a0>,\n <keras.layers.core.activation.Activation at 0x164271be0>,\n <keras.layers.convolutional.Conv2D at 0x1642912b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164291af0>,\n <keras.layers.core.activation.Activation at 0x1642a9070>,\n <keras.layers.convolutional.Conv2D at 0x1642a9640>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642a9850>,\n <keras.layers.core.activation.Activation at 0x164266190>,\n <keras.layers.convolutional.Conv2D at 0x1642716d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16429fbb0>,\n <keras.layers.merge.Add at 0x16421c9d0>,\n <keras.layers.core.activation.Activation at 0x1641ac8e0>,\n <keras.layers.convolutional.Conv2D at 0x164224310>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164238dc0>,\n <keras.layers.core.activation.Activation at 0x164207f70>,\n <keras.layers.convolutional.Conv2D at 0x1642b1df0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642b1cd0>,\n <keras.layers.core.activation.Activation at 0x1642b2370>,\n <keras.layers.convolutional.Conv2D at 0x164233850>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642b3970>,\n <keras.layers.merge.Add at 0x1642b7280>,\n <keras.layers.core.activation.Activation at 0x1642b78b0>,\n <keras.layers.convolutional.Conv2D at 0x1642b65e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642b6d60>,\n <keras.layers.core.activation.Activation at 0x1642b2820>,\n <keras.layers.convolutional.Conv2D at 0x1642c3fa0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642b3460>,\n <keras.layers.core.activation.Activation at 0x1642d6310>,\n <keras.layers.convolutional.Conv2D at 0x1642d6d30>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642dc130>,\n <keras.layers.merge.Add at 0x1642df100>,\n <keras.layers.core.activation.Activation at 0x1642df910>,\n <keras.layers.convolutional.Conv2D at 0x1642dc4f0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642dc850>,\n <keras.layers.core.activation.Activation at 0x1642f0130>,\n <keras.layers.convolutional.Conv2D at 0x1642f0520>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642f0910>,\n <keras.layers.core.activation.Activation at 0x1643001c0>,\n <keras.layers.convolutional.Conv2D at 0x1643009a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1643043d0>,\n <keras.layers.merge.Add at 0x16430a3a0>,\n <keras.layers.core.activation.Activation at 0x1642f0b20>,\n <keras.layers.convolutional.Conv2D at 0x1643002e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164300790>,\n <keras.layers.core.activation.Activation at 0x16431e3a0>,\n <keras.layers.convolutional.Conv2D at 0x16431e250>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x16431ee80>,\n <keras.layers.core.activation.Activation at 0x1642e7790>,\n <keras.layers.convolutional.Conv2D at 0x1642df520>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642c4340>,\n <keras.layers.merge.Add at 0x16423f190>,\n <keras.layers.core.activation.Activation at 0x1642b02b0>,\n <keras.layers.convolutional.Conv2D at 0x164324dc0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164324100>,\n <keras.layers.core.activation.Activation at 0x164328460>,\n <keras.layers.convolutional.Conv2D at 0x164328730>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164328610>,\n <keras.layers.core.activation.Activation at 0x16432d400>,\n <keras.layers.convolutional.Conv2D at 0x1642367f0>,\n <keras.layers.convolutional.Conv2D at 0x16432dee0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1642913d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164328970>,\n <keras.layers.merge.Add at 0x1643371f0>,\n <keras.layers.core.activation.Activation at 0x164337a00>,\n <keras.layers.convolutional.Conv2D at 0x164332370>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164326e80>,\n <keras.layers.core.activation.Activation at 0x165e47220>,\n <keras.layers.convolutional.Conv2D at 0x165e47a00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x164326460>,\n <keras.layers.core.activation.Activation at 0x165e531f0>,\n <keras.layers.convolutional.Conv2D at 0x165e539d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x165e5a5b0>,\n <keras.layers.merge.Add at 0x165e67160>,\n <keras.layers.core.activation.Activation at 0x165e67ca0>,\n <keras.layers.convolutional.Conv2D at 0x165e53280>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x165e61250>,\n <keras.layers.core.activation.Activation at 0x165e73460>,\n <keras.layers.convolutional.Conv2D at 0x165e73220>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x165e73f40>,\n <keras.layers.core.activation.Activation at 0x165e67dc0>,\n <keras.layers.convolutional.Conv2D at 0x165e7df10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x166783b20>,\n <keras.layers.merge.Add at 0x16678e490>,\n <keras.layers.core.activation.Activation at 0x16678ea90>,\n <keras.layers.pooling.GlobalAveragePooling2D at 0x166783be0>]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ks/m0btnx4d7j38phjw29dfybvw0000gn/T/ipykernel_2094/3326332652.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit_history = model.fit_generator(\n",
      "2022-08-14 22:33:10.827105: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "301/301 [==============================] - 1244s 4s/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 1261s 4s/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdelrahmanibrahim/miniforge3/envs/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}